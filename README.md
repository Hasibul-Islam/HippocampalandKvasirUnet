# ðŸ§© UNet Image Segmentation Project

A clean and modular PyTorch implementation of **UNet** for [Hippocampal!](https://rutgers.box.com/v/HippocampalROISegDataset) image segmentation.  And also Implementation on [Kvasir!](https://www.kaggle.com/datasets/debeshjha1/kvasirseg?resource=download). Dataset. 


---

## ðŸš€ Features

- Fully modular project architecture (datasets, models, utils, config, training)
- Custom **Dice Loss** for segmentation
- **Early stopping** and best-model checkpointing
- Train/validation/test pipeline with augmentations (Albumentations)
- GPU/CPU auto-selection
- Ready for experimentation and dataset extension

---

## ðŸ“ Project Structure

```
unet_segmentation_project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/                 # Input images (.tif)
â”‚   â””â”€â”€ masks/                  # Ground truth masks (mask.png)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ unet.py                 # UNet architecture
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ segmentation_dataset.py # Dataset class + augmentations
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ losses.py               # DiceLoss and other metrics
â”‚   â”œâ”€â”€ train_eval.py           # Training & evaluation loops
â”‚   â””â”€â”€ config.py               # Global constants and hyperparameters
â”‚
â”œâ”€â”€ train.py                    # Main training script
â”œâ”€â”€ test.py                     # (Optional) Inference script
â”œâ”€â”€ requirements.txt            # Library dependencies
â””â”€â”€ README.md                   # Project documentation
```

---



## âš™ï¸ Installation Guide

### 1ï¸âƒ£ Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate      # Linux / macOS
venv\Scripts\activate         # Windows
```

---

### 2ï¸âƒ£ Install PyTorch Nightly (CUDA 12.8)

> âš ï¸ You must install PyTorch **manually** if youâ€™re using the nightly CUDA build.

```bash
pip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128
```

---

### 3ï¸âƒ£ Install other dependencies

```bash
pip install -r requirements.txt
```

#### requirements.txt

```
# PyTorch installed manually (nightly build, CUDA 12.8)
# Install separately using:
# pip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128

albumentations
opencv-python
numpy
scikit-learn
tqdm
```

---

## ðŸ§© Dataset Setup

Organize your dataset as follows:

```
data/
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ sample1.tif
â”‚   â”œâ”€â”€ sample2.tif
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ masks/
    â”œâ”€â”€ sample1_mask.png
    â”œâ”€â”€ sample2_mask.png
    â””â”€â”€ ...
```

> Image names must match mask names (except the `_mask` suffix).

Example:
```
image: sample1.tif
mask:  sample1_mask.png
```

---

## ðŸ§  Training

Run the main training scripts:

1. For Cohort1 Multiplexed
```bash
python trainCohortMul.py
```

The script will:
- Split the dataset into **train/val/test** sets (15% test, 15% val)
- Train the UNet model
- Save the **best model** as `unet_bestCohortMul.pth` using early stopping

Youâ€™ll see progress and loss updates directly in the terminal.

---

2. For Cohort1 NeuN
```bash
python trainCohortMul.py
```

The script will:
- Split the dataset into **train/val/test** sets (15% test, 15% val)
- Train the UNet model
- Save the **best model** as `unet_bestCohortNeuN.pth` using early stopping

Youâ€™ll see progress and loss updates directly in the terminal.

---

3. For Extended
```bash
python trainCohortMul.py
```

The script will:
- Split the dataset into **train/val/test** sets (15% test, 15% val)
- Train the UNet model
- Save the **best model** as `unet_bestExtended.pth` using early stopping

Youâ€™ll see progress and loss updates directly in the terminal.

---

4. For Kvasir Dataset
```bash
python trainCohortMul.py
```

The script will:
- Split the dataset into **train/val/test** sets (15% test, 15% val)
- Train the UNet model
- Save the **best model** as `unet_bestKvasir.pth` using early stopping

Youâ€™ll see progress and loss updates directly in the terminal.

---

## ðŸ“ˆ Configuration

Edit `utils/config.py` to adjust hyperparameters and paths:

```python
EPOCHS = 120
BATCH_SIZE = 4
LEARNING_RATE = 2e-4
PATIENCE = 20
IMAGE_DIR = "data/images"
MASK_DIR = "data/masks"
MODEL_PATH = "unet_best.pth"
```

---

## ðŸ§ª Testing / Inference (Optional)

For Testing the scores on different dataset


1. For Cohort1 Multiplexed
```bash
python testCohortMul.py 
```

It will create the results as txt file in results folder as resultCohortMul.txt. 

2. For Cohort1 NeuN
```bash
python testCohortNeuN.py 
```

It will create the results as txt file in results folder as resultCohortNeuN.txt. 

3. For Extended
```bash
python testExtended.py 
```

It will create the results as txt file in results folder as resultExtended.txt. 

4. For Kvasir
```bash
python testCohortNeuN.py 
```

It will create the results as txt file in results folder as resultKvasir.txt. 


---

## ðŸ§± Model Overview

The architecture is a **standard UNet**:

- Encoder: 4 downsampling stages (64 â†’ 128 â†’ 256 â†’ 512)
- Bottleneck: 1024 filters
- Decoder: skip connections and upsampling
- Output: `n_classes` channels (2 for binary segmentation)

**Loss Function:** Dice Loss  
**Optimizer:** Adam  
**Scheduler:** None (constant LR, but easy to add)

---

## ðŸ§© Example Training Log

```
Epoch 5/50
Train Loss: 0.3241, Val Loss: 0.2987
âœ… Model saved (Epoch 5, Val Loss 0.2987)

Epoch 6/50
Train Loss: 0.3178, Val Loss: 0.2975
âœ… Model saved (Epoch 6, Val Loss 0.2975)
```

When early stopping triggers:

```
â›” Early stopping. Best epoch: 6, Val Loss: 0.2975
```

---

## ðŸ’¾ Checkpoints

After training, youâ€™ll find:

```
unet_best.pth  # best-performing model weights
```

You can load it later for inference:

```python
model.load_state_dict(torch.load("unet_best.pth"))
```

---

## ðŸ§  Author Notes

Md Hasibul Islam
MSc. Automotive Software Engineering, TU Chemnitz

- Code and Dataset is used for research work
- Original Dataset Collected from [Mehedi Azim!](https://github.com/MehediAzim)

---

## ðŸ§© Future Improvements


- Add learning rate scheduler
- Add TensorBoard logging

---

## ðŸªª License

MIT License â€” free to use and modify with credit.

---

